# ---------------------------
# -------- GENERIC ----------

PROJECT_NAME=ginco

ENVIRONMENT=preprod

TRAEFIK_NETWORK=traefik-ginco-depobio-preprod

#ACME_EMAIL="" # required for valid https certificates

# ---------------------------
# ------- COMPOSE GN --------

APP=ginco-nationale

INSTANCE_SUB_FOLDER=nationale/

BASE_PROTOCOL=http

#HOST=preprod-swarm-0.patnat.mnhn.fr
#HOSTPORT="${HOST}"  # set to ${HOST}:${HTTPS_PORT} if HTTPS_PORT is different from 443

#STACK_PORT=8185

#UID=1000
#GID=1000

GEONATURE_SUPERGRANT_ARGS=--group --nom Grp_admin

GEONATURE_DB_LOCAL_SRID=4326
GEONATURE_DB_ADD_SAMPLE_DATA=false
GEONATURE_DB_INSTALL_BDC_STATUTS=true
GEONATURE_DB_INSTALL_SIG_LAYERS=true
GEONATURE_DB_INSTALL_GRID_LAYER=true
GEONATURE_DB_INSTALL_REF_SENSITIVITY=true
GEONATURE_DB_INSTALL_USERSHUB_SAMPLES=true
GEONATURE_DB_INSTALL_TAXHUB_SAMPLES=true

GEONATURE_SKIP_POPULATE_DB=false

POSTGRES_USER=geonatadmin
POSTGRES_PASSWORD=geonatpasswd
POSTGRES_HOST=postgres
POSTGRES_DB=geonature2db
POSTGRES_PORT_PUBLISHED=5432

USERSHUB_IMAGE=ghcr.io/pnx-si/usershub:2.4.3
USERSHUB_PROTOCOL=http
USERSHUB_HOST=preprod-swarm-0.patnat.mnhn.fr
USERSHUB_HOSTPORT=preprod-swarm-0.patnat.mnhn.fr:8185
USERSHUB_PREFIX=/usershub

TAXHUB_IMAGE=ghcr.io/pnx-si/taxhub:1.14.1
TAXHUB_PROTOCOL=http
TAXHUB_HOST=preprod-swarm-0.patnat.mnhn.fr
TAXHUB_HOSTPORT=preprod-swarm-0.patnat.mnhn.fr:8185
TAXHUB_PREFIX=/taxhub
TAXHUB_API_PREFIX=/taxhub/api

GEONATURE_BACKEND_EXTRA_IMAGE=ghcr.io/pnx-si/geonature-backend-extra@sha256:1f894b0d53807ee2415df6e36610fc7ef951a10859c1adf1899226051e82bdf8
GEONATURE_BACKEND_PROTOCOL=http
GEONATURE_BACKEND_HOST=preprod-swarm-0.patnat.mnhn.fr
GEONATURE_BACKEND_HOSTPORT=preprod-swarm-0.patnat.mnhn.fr:8185
GEONATURE_BACKEND_PREFIX=/geonature/api

GEONATURE_FRONTEND_EXTRA_IMAGE=ghcr.io/pnx-si/geonature-frontend-extra:2.14.2
GEONATURE_FRONTEND_PROTOCOL=http
GEONATURE_FRONTEND_HOST=preprod-swarm-0.patnat.mnhn.fr
GEONATURE_FRONTEND_HOSTPORT=preprod-swarm-0.patnat.mnhn.fr:8185
GEONATURE_FRONTEND_PREFIX=/geonature

# - Resources

# CPUs
# TOTAL: 7 to 9.5 as a starting point
# TOTAL Without geonature-install-db: 5.5 to 8, as a starting point
# CURRENT: 10
# CURRENT Without geonature-install-db: 8.5
#-----
# GUNICORN: nb_cpus = (nb_workers * nb_threads - 1)/2
#-
# POSTGRES: depends on complexity of processed queries and level of concurrency
#         recommended: 1 as a starting point
#         recommended: 2 or more, for higher concurrency or complex query workloads
#-
# REDIS: Redis is single-threaded by design, meaning it can only utilize a single CPU core at a time
#        CPU usage is low for a Redis message broker (broker for Celery worker)
#        depends on overall system load and number of concurrent connections to Redis
#        recommended: 0.5 to 1 as a starting point
#-
# CELERY: the number of CPUs give the number of workers that are actually started
#         recommended: 1 to 2 CPUs as a starting point
#-
# NGINX: Nginx serving static files is not CPU-intensive. 
#        actually depends on the expected traffic and usage patterns
#        recommended: 0.5 CPUs as a starting point
#---
# GUNICORN: (2 * 2 - 1)/2 = 1.5
GEONATURE_INSTALL_DB_CPUS=1.5
# POSTGRES: 1, as a starting point
#           2 or more, to  improve Synthese performance
POSTGRES_CPUS=4
# REDIS: 0.5, as a starting point
REDIS_CPUS=0.5
# CELERY: 1, as a starting point
GEONATURE_WORKER_CPUS=1
# GUNICORN: (2 * 2 - 1)/2 = 1.5
GEONATURE_BACKEND_CPUS=1.5
# NGINX: 0.5, as a starting point
GEONATURE_FRONTEND_CPUS=0.5
# GUNICORN: (1 * 1 - 1)/2 = 0 --> 0.5
TAXHUB_CPUS=0.5
# GUNICORN: (1 * 1 - 1)/2 = 0 --> 0.5
USERSHUB_CPUS=0.5

# Memory
# TOTAL: 5.25 to 8 GB, as a starting point
# TOTAL Without geonature-install-db: 4.75 to 7.5 GB, as a starting point
# CURRENT: 14.75 GB
# CURRENT Without geonature-install-db: 14.25 GB
#-------
# GUNICORN: 
#        recommended: at least 256m per worker as a starting point
#-
# POSTGRES: depends on the size of datasets and the complexity of queries
#        recommended: 2g to 4g, as a starting point
#        // must adjust PostgreSQL configuration accordingly:
#           - shared_buffers = 25% * memory --> PostgreSQL caching
#               default: 128MB
#               with 4g: 25% * 4g = 1GB            
#           - work_mem --> internal sort operations and hash tables before writing to temporary disk files
#               // number of concurrent operations and memory available
#               default: 4MB
#               with 4g: 16MB
#           - maintenance_work_mem --> maintenance operations like `VACUUM` and `CREATE INDEX`
#               // size of datasets and indexes
#               default: 64MB
#               with 4g: 128MB
#           - effective_cache_size = 50 to 75% * memory --> disk caching by the operating system and within the database itself
#               default: 4GB
#               with 4g: 75% * 4g = 3GB
#-
# REDIS: depends on the number of tasks in the queue,
#           the size of the messages being sent,
#           and any other data stores in Redis (such as result backend data if configured)
#        recommended: 512m as a starting point
# CELERY: 
#        recommended: 512m to 1g per worker as a starting point
#-
# NGINX: Nginx serving static files requires minimal memory
#        recommended: 256m to 512m as a starting point
#---
# GUNICORN: (256m * 2) = 512m, as a starting point
GEONATURE_INSTALL_DB_MEMORY=512m
# POSTGRES: 2g, as a starting point
#           4g, to try improve Synthese performance // but PostgreSQL certainly must be configured
#           8g, to try improve global performance and stick to the possibly allowed RAM on old servers // coherent with PostgreSQL configuration
POSTGRES_MEMORY=8g
# REDIS: 512m, as a starting point
REDIS_MEMORY=512m
# CELERY: (1g * 1) = 1g, as a starting point
GEONATURE_WORKER_MEMORY=1g
# GUNICORN: (256m * 2) = 512m, as a starting point
GEONATURE_BACKEND_MEMORY=4g
# NGINX: 256m, as a starting point
GEONATURE_FRONTEND_MEMORY=256m
# GUNICORN: (256m * 1) = 256m, as a starting point
TAXHUB_MEMORY=256m
# GUNICORN: (256m * 1) = 256m, as a starting point
USERSHUB_MEMORY=256m

# PostgreSQL configuration
# shared_buffers: 
#   default: 128MB
#   recommended: 25% * POSTGRES_MEMORY
#   current: 25% * 4 = 1GB
# POSTGRES_SHARED_BUFFERS=1GB
# # work_mem:
# #   default: 4MB
# #   recommended: no more than 25% to 33% of POSTGRES_MEMORY
# #                (25% * POSTGRES_MEMORY) / (nb_concurrent_connections * nb_concurrent_sort_and_hash_operations_by_connection)
# #   current: (25% * 4GB) / (50 * 2) = 10MB
# POSTGRES_WORK_MEM=10MB
# # maintenance_work_mem:
# #   default: 64MB
# #   recommended: 5% to 10% of POSTGRES_MEMORY
# #   current: 10% * 4 = 400MB
# POSTGRES_MAINTENANCE_WORK_MEM=400MB
# # effective_cache_size:
# #   default: 4GB
# #   recommended: 50% to 75% * POSTGRES_MEMORY
# #   current: 75% * 4 = 3GB
# POSTGRES_EFFECTIVE_CACHE_SIZE=3GB
# ---
# Old PostgreSQL configuration (configured by Mathieu Manceau on old servers)
# // 8GB RAM and 4 CPU cores for `postgres` service
POSTGRES_LISTEN_ADDRESSES=*
POSTGRES_TCP_KEEPALIVES_IDLE=60
POSTGRES_TCP_KEEPALIVES_INTERVAL=20
POSTGRES_TCP_KEEPALIVES_COUNT=10
POSTGRES_MAX_CONNECTIONS=200
POSTGRES_SHARED_BUFFERS=2GB
POSTGRES_EFFECTIVE_CACHE_SIZE=6GB
POSTGRES_MAINTENANCE_WORK_MEM=512MB
POSTGRES_CHECKPOINT_COMPLETION_TARGET=0.9
POSTGRES_WAL_BUFFERS=16MB
POSTGRES_DEFAULT_STATISTICS_TARGET=100
POSTGRES_RANDOM_PAGE_COST=1.1
POSTGRES_EFFECTIVE_IO_CONCURRENCY=300
POSTGRES_WORK_MEM=5242kB
POSTGRES_HUGE_PAGES=off
POSTGRES_MIN_WAL_SIZE=1GB
POSTGRES_MAX_WAL_SIZE=4GB
POSTGRES_MAX_WORKER_PROCESSES=4
POSTGRES_MAX_PARALLEL_WORKERS_PER_GATHER=2
POSTGRES_MAX_PARALLEL_WORKERS=4
POSTGRES_MAX_PARALLEL_MAINTENANCE_WORKERS=2

# Celery configuration
# concurrency:
#   /!\ default (if not specified in the Celery command): number of CPU cores on the host 
#   recommended: 1 as a starting point
#                should be chosen given the memory and CPUs allocated to the service `geonature-worker` 
#                   and the expected number, nature and complexity of the concurrent tasks.
#                may be deduced as (where ⌊.⌋ is the floor function): ⌊(REDIS_MEMORY / 250m)⌋
#   current: 1 (starting point)
CELERY_CONCURRENCY=1